{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9aaxiSJg60h"
   },
   "source": [
    "# Introduction to Neural Networks with TensorFlow\n",
    "\n",
    "텐서플로우는 Numpy의 배열과 유사한 자료구조인 tensor를 사용한다.   \n",
    "\n",
    "tensorflow는 backpropagation을 수행하기 위한 자동 미분 기능을 가지고 있으며 직관적으로 활용할 수 있는 high-level API를 제공한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6WXEV-OiFY7"
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "Deep Learning은 1950년 후반에 등장한 artificial neural networks를 기반으로 하고 있다.   \n",
    "network는 \"neurons.\" 또는 unit 이라고 부르는 단위로 구성된다. 각 unit은 weighted inputs을 입력으로 받는다. 이 weighted inputs 은 선형 결합(linear combination)을 거쳐 하나로 합쳐진다. 그리고 나서 activation function(활성화 함수)를 통과하여 unit의 output 출력된다.\n",
    "\n",
    "<img src=\"../assets/simple_neuron.png\" width=400px>\n",
    "\n",
    "수학적으로 표기하면 다음과 같다. \n",
    "\n",
    "$$\n",
    "y = f(h)\n",
    "$$\n",
    "\n",
    "여기서, \n",
    "\n",
    "$$\n",
    "h = w_1 x_1 + w_2 x_2 + b = \\sum_{i=1}^2 w_i x_i + b\n",
    "$$\n",
    "\n",
    "$b = w_0x_0$ ㄹ고 하면,  $h$ 는 두 vector의 dot/inner product 로 표기된다.\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_0 \\, x_1 \\, x_2\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_0 \\\\\n",
    "           w_1 \\\\\n",
    "           w_2\n",
    "\\end{bmatrix} = w_0 x_0 + w_1 x_1 + w_2 x_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcBD-UAaiaUc"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "*tensors*는 행렬을 일반화하여 표현하는 수학적 용어이다.\n",
    "\n",
    "* vector : 1차원 텐서\n",
    "* matrix : 2차원 텐서 \n",
    "* 다차원 행렬 : n차원 텐서 \n",
    "\n",
    "\n",
    "neural network를 구성하는 기본 data structure가 tensor 이다. \n",
    "\n",
    "\n",
    "<img src=\"../assets/tensor_examples.svg\" width=600px>\n",
    "\n",
    "\n",
    "기본을 익히기 위해 tensor를 사용하여 간단한 신경망 모형을 생성해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pt6qo5hiesm7"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adTiqrSxkPvL"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfzIw49JwZb0"
   },
   "outputs": [],
   "source": [
    "# 파이썬에서 로그 레벨 - 로그는 중요도에 따라 서로 다른 레벨\n",
    "# DEBUG < INFO < WARNING < ERROR < CRITICAL\n",
    "# logging 시스템의 레벨은 WARNING\n",
    "# ERROR로 설정하면 warning은 무시된다.\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyZjjOb-V4eo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version:', tf.__version__) # 텐서플로우 버전확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVTYgypBfx2a"
   },
   "source": [
    "## Single Layer Neural Network\n",
    "\n",
    "간단한 신경망 모형을 생성하기 위한 랜덤 샘플 데이터를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDJArguZkLPJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " tf.Tensor([[ 0.5983449   0.06276207  0.14631742  0.48481876 -0.23572342]], shape=(1, 5), dtype=float32)\n",
      "\n",
      "Weights:\n",
      " tf.Tensor([[-2.2733312  -1.6592104  -0.2633568  -0.80923414  1.0294315 ]], shape=(1, 5), dtype=float32)\n",
      "\n",
      "Bias:\n",
      " tf.Tensor([[1.5749502]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed so things are reproducible\n",
    "tf.random.set_seed(7) \n",
    "\n",
    "# Create 5 random input features\n",
    "features = tf.random.normal((1, 5))\n",
    "\n",
    "# Create random weights for our neural network\n",
    "weights = tf.random.normal((1, 5))\n",
    "\n",
    "# Create a random bias term for our neural network\n",
    "bias = tf.random.normal((1, 1))\n",
    "\n",
    "print('Features:\\n', features)\n",
    "print('\\nWeights:\\n', weights)\n",
    "print('\\nBias:\\n', bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7o-2IomPkZx6"
   },
   "source": [
    "실제 데이터를 사용해서 실습하기 앞서 임의의 랜덤 샘플 데이터로 실습을 진행한다.\n",
    "\n",
    "\n",
    "`tf.Tensor` objects는  data type 과 shape을 가진다. \n",
    "\n",
    "* `features = tf.random.normal((1, 5))` `(1, 5)`인 표준 정규분포를 따르는 랜덤 값으로 텐서를 생성한다.\n",
    "\n",
    "* `weights = tf.random.normal((1, 5))` `(1, 5)`인 표준 정규분포를 따르는 랜덤 값으로 텐서를 생성한다.\n",
    "\n",
    "* `bias = tf.random.normal((1, 1))` 표준 정규분포를 따르는 임의의 단일한 값을 가지는 텐서를 생성한다. \n",
    "\n",
    "\n",
    "텐서플로우의 텐서는 numpy배열과 유사하게 연산이 가능하다. 사용법도 numpy 배열과 유사하다. 위에서 network에서 사용할 텐서를 임의의 값으로 생성하였다.\n",
    "\n",
    "이제 아래에서 활성화 함수로 sigmoid 함수를 작성해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmOi7zjFgsMM"
   },
   "outputs": [],
   "source": [
    "def sigmoid_activation(x):\n",
    "    \"\"\" Sigmoid activation function\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: tf.Tensor. Must be one of the following types: bfloat16, half, float32, float64, complex64, complex128.\n",
    "    \"\"\"\n",
    "    return 1/(1+tf.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57QrwP-0gny1"
   },
   "source": [
    "single layer neural network를 생성할 수 있다.\n",
    "\n",
    "> **실습하기**: 앞서 생성한 `features` ,`weights`, `bias`를 사용하여 신경망 모형을 작성한다. NumPy와 유사하게, TensorFlow 에서 `tf.multiply(a, b)` 를 통해 텐서`a` 와 텐서 `b`의 요소별 곱(multiply)를 구할 수 있다.`tf.reduce_sum(x)` 를 사용하면 tensor `x`의 모든 요소에 대한 합을 구할 수 있다. 활성화 함수로는 앞서 생성한 `sigmoid_activation` function를 사용하도록 한다.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qujbYK1nkaW-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:\n",
      " tf.Tensor([[0.3628656]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "y = sigmoid_activation(tf.reduce_sum(tf.multiply(features, weights)) + bias)\n",
    "\n",
    "print('label:\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gx6LpDRakgOD"
   },
   "source": [
    "각 텐서의 요소별 곱(multiply) 대신에 matrix multiplication을 사용해도 동일한 결과를 생성할 수 있다.\n",
    "\n",
    "\n",
    "matrix multiplication를 사용하는 편이 연산의 성능 면에서는 더 좋다. \n",
    "\n",
    "\n",
    "`tf.matmul()`를 사용하면 features 와 weights를 matrix multiplication으로 처리 할 수 있다. 대신에 이때 tensor의 shape을 잘 맞추어야만 한다. 맞지 않으면 다음고 같은 에러를 만날 수 있다.\n",
    "\n",
    "```python\n",
    ">> tf.matmul(features, weights)\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "InvalidArgumentError                      Traceback (most recent call last)\n",
    "<ipython-input-7-66a4fe44f20b> in <module>()\n",
    "      1 \n",
    "----> 2 y = sigmoid_activation(tf.matmul(features, weights) + bias)\n",
    "\n",
    "2 frames\n",
    "/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\n",
    "\n",
    "InvalidArgumentError: Matrix size-incompatible: In[0]: [1,5], In[1]: [1,5] [Op:MatMul] name: MatMul/\n",
    "```\n",
    "\n",
    "위의 에러는 인공 신경망 모형에서 흔히 만날 수 있는 에러인데 matrix multiplication에서 텐서의 shape이 맞지 않을 경우에 해당 에러가 난다.   \n",
    "\n",
    "이러한 에러는 텐서의 shape(=dim)정보가 맞지 않기 때문에 발생한다.  \n",
    "\n",
    "다음과 같은 사항을 반드시 주의하자.\n",
    "- 첫번째 tensor의 column의 갯수와  두번째 tensor의 row 갯수가 서로 일치해야 한다.\n",
    "- 만약 `features` 가 `weights` 같은 shape `(1, 5)` 라고 하면 `weights` 의 shape를 matrix multiplication 에 맞도록 바꾸어야 한다.\n",
    "\n",
    "**Note:** `tensor.shape`로 shape를 확인할 수 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5flC0NB5uSlk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: (1, 5)\n",
      "Weights Shape: (1, 5)\n",
      "Bias Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Features Shape:', features.shape)\n",
    "print('Weights Shape:', weights.shape)\n",
    "print('Bias Shape:', bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lC0vZqQWvBon"
   },
   "source": [
    "`weights` 의 shape를 matrix multiplication 에 맞도록 바꾸어야 한다.  \n",
    "\n",
    "`tf.matmul(a,b)` function를 사용해서 matrix multiplication을 수행한다. 이때 shape을 맞추기 위해 `transpose_a`, `transpose_b` arguments 를 사용하면 해당 텐서의 shape을 실제로 변경하지 않고 텐서를 transpose(행과 열을 바꿈)하여 matmul을 수행한다. 이 예제에서는 `transpose_b = True` 를 사용하여 `weights` tensor를 `(1,5)`에서 `(5,1)` 로 변경하여 matmul을 수행하도록 한다.\n",
    "\n",
    "\n",
    "> **실습** : 위와 동일하게 y를 matrix multiplication로 구현하시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIQOahT4kg4H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:\n",
      " tf.Tensor([[0.3628656]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Solution\n",
    "y = sigmoid_activation(tf.matmul(features, weights, transpose_b = True) + bias)\n",
    "\n",
    "print('label:\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxzezexmkpzs"
   },
   "source": [
    "확인해보면, `transpose_b = True` argument를 사용해서 `weights` tensor의 shape을 실제로 변경하지는 않았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoESCJcLkrI5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Shape: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Weights Shape:', weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktu4Jfq3kzWx"
   },
   "source": [
    "## Multi-Layer Neural Network\n",
    "\n",
    "\n",
    "개별적인 layer를 여러개 쌓아서 Multi-layer neural network를 구성할 수 있다. layer의 output이 다음 layer의 input이 된다. 여러개의 input units과 output units이 있으므로 weights 는 matrix로 표현된다.\n",
    "\n",
    "<img src='../assets/multilayer_diagram_weights.png' width=450px>\n",
    "\n",
    "위 그림에서 맨 밑의 첫 layer는 **input layer** 이다. 중간에 있는 layer는 **hidden layer** 이다.그리고 마지막 layer는 **output layer**이다. 수학적으로 표기하면 다음과 같다.:\n",
    "\n",
    "$$\n",
    "\\vec{h} = [h_1 \\, h_2] = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots \\, x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_{11} & w_{12} \\\\\n",
    "           w_{21} &w_{22} \\\\\n",
    "           \\vdots &\\vdots \\\\\n",
    "           w_{n1} &w_{n2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "network의 output을 수식으로 간단히 표현하면 다음과 같다.\n",
    "\n",
    "$$\n",
    "y =  f_2 \\! \\left(\\, f_1 \\! \\left(\\vec{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWRfPCIKkwZb"
   },
   "outputs": [],
   "source": [
    "# Set the random seed so things are reproducible\n",
    "tf.random.set_seed(7) \n",
    "\n",
    "# Create 3 random input features\n",
    "features = tf.random.normal((1,3))\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units \n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Create random weights connecting the inputs to the hidden layer\n",
    "W1 = tf.random.normal((n_input,n_hidden))\n",
    "\n",
    "# Create random weights connecting the hidden layer to the output layer\n",
    "W2 = tf.random.normal((n_hidden, n_output))\n",
    "\n",
    "# Create random bias terms for the hidden and output layers\n",
    "B1 = tf.random.normal((1,n_hidden))\n",
    "B2 = tf.random.normal((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCRRqGFik5N8"
   },
   "source": [
    "> **실습하기:** multi-layer network의 output을 작성해 보시오. weights는 `W1` & `W2`, 그리고  bias는, `B1` & `B2`으로 표현하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKKfk_jyk5_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.10678572]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Solution\n",
    "h = sigmoid_activation(tf.matmul(features, W1) + B1)\n",
    "output = sigmoid_activation(tf.matmul(h, W2) + B2)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Q1QzBpFlAFj"
   },
   "source": [
    "앞선 실습을 제대로 작성하였다면 output은 다음과 같다: `tf.Tensor([[0.10678572]], shape=(1, 1), dtype=float32)`\n",
    "\n",
    "hidden units의 갯수는 **hyperparameter**이다.  hidden layers 와 hidden units를 많이 할수록 복잡한 문제를 풀수 있는 network capacity가 증가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qASlsncVlDRi"
   },
   "source": [
    "## NumPy to TensorFlow and Back\n",
    "\n",
    "tensor는 numpy의 `ndarrays` 와 호환이 된다. `tf.convert_to_tensor()`를 사용하면 NumPy ndarray를 tensor로 변환할 수 있다. `.numpy()`  메소드를 사용하면 tensor를 NumPy array로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MHSE0uqlAsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.05555019 0.88001085 0.37259558]\n",
      " [0.99069457 0.73259237 0.18435513]\n",
      " [0.7141118  0.78794829 0.37554902]\n",
      " [0.56149971 0.33285178 0.7345163 ]]\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed so things are reproducible\n",
    "tf.random.set_seed(7) \n",
    "\n",
    "a = np.random.rand(4,3)\n",
    "\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VceuFk3GlKKL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.05555019 0.88001085 0.37259558]\n",
      " [0.99069457 0.73259237 0.18435513]\n",
      " [0.7141118  0.78794829 0.37554902]\n",
      " [0.56149971 0.33285178 0.7345163 ]], shape=(4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "b = tf.convert_to_tensor(a)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOh6E9SBlMzj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.05555019 0.88001085 0.37259558]\n",
      " [0.99069457 0.73259237 0.18435513]\n",
      " [0.7141118  0.78794829 0.37554902]\n",
      " [0.56149971 0.33285178 0.7345163 ]]\n"
     ]
    }
   ],
   "source": [
    "c = b.numpy()\n",
    "\n",
    "print(type(c))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ua9iXmXBlP4M"
   },
   "source": [
    "tensor 의 value를 변경하여도 ndarray의 value는 변경되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BC_O_BcOlTHa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2.22200767 35.20043392 14.903823  ]\n",
      " [39.62778298 29.30369474  7.37420506]\n",
      " [28.56447189 31.51793176 15.02196063]\n",
      " [22.45998845 13.31407135 29.38065216]], shape=(4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Multiply TensorFlow Tensor by 40\n",
    "b = b * 40\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1gxSglFlV2R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05555019, 0.88001085, 0.37259558],\n",
       "       [0.99069457, 0.73259237, 0.18435513],\n",
       "       [0.7141118 , 0.78794829, 0.37554902],\n",
       "       [0.56149971, 0.33285178, 0.7345163 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array stays the same\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tkHnTSbNKdE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05555019, 0.88001085, 0.37259558],\n",
       "       [0.99069457, 0.73259237, 0.18435513],\n",
       "       [0.7141118 , 0.78794829, 0.37554902],\n",
       "       [0.56149971, 0.33285178, 0.7345163 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array stays the same\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_vdtpxnlYUN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.05555019 1.88001085 1.37259558]\n",
      " [1.99069457 1.73259237 1.18435513]\n",
      " [1.7141118  1.78794829 1.37554902]\n",
      " [1.56149971 1.33285178 1.7345163 ]]\n"
     ]
    }
   ],
   "source": [
    "# Add 1 to NumPy ndarray\n",
    "a = a + 1\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdtiRFFDlblU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2.22200767 35.20043392 14.903823  ]\n",
      " [39.62778298 29.30369474  7.37420506]\n",
      " [28.56447189 31.51793176 15.02196063]\n",
      " [22.45998845 13.31407135 29.38065216]], shape=(4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Tensor stays the same\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMzweL10wZcw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05555019, 0.88001085, 0.37259558],\n",
       "       [0.99069457, 0.73259237, 0.18435513],\n",
       "       [0.7141118 , 0.78794829, 0.37554902],\n",
       "       [0.56149971, 0.33285178, 0.7345163 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array stays the same\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 1 - Introduction to Neural Networks with TensorFlow (Solution).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
