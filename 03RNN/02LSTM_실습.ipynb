{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsEDR5QCl0Et"
   },
   "source": [
    "# LSTM 실습\n",
    "LSTM(Long Short Term Memory)는 좀 더 긴 타임 스텝의 데이터를 처리하기 위해 고안되었다. gradient vanishing 문제를 극복하여 성공적으로 모델링 할 수 있다. \n",
    "\n",
    "앞 선 실습에서 SimpleRNN 클래스를 LSTM 클래스로 바꾸기만 하면 LSTM 순환 신경망을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6i2jodhCtp-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRWPdkUIhN26"
   },
   "source": [
    "# 훈련데이터 준비\n",
    "\n",
    "* IMDB 데이터 사용 - Word Embedding은 단어 벡터의 크기를 임의로 조정하므로 사용되는 단어의 갯수에 크게 영향을 받지 않는다.\n",
    "\n",
    "* 이 경우 사용되는 단어의 갯수를 1000으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AagDOCDfcqOq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZDfoEg_ZE_0"
   },
   "outputs": [],
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test) = imdb.load_data(skip_top=20, num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Xn2krTqY34v"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpORaDiIc8hn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 43, 530, 973, 65, 458, 66, 173, 36, 256, 25, 100, 43, 838, 112, 50, 670, 35, 480, 284, 150, 172, 112, 167, 336, 385, 39, 172, 546, 38, 447, 192, 50, 147, 22, 469, 22, 71, 87, 43, 530, 38, 76, 22, 515, 626, 62, 386, 316, 106, 480, 66, 33, 130, 38, 619, 25, 124, 51, 36, 135, 48, 25, 33, 22, 215, 28, 77, 52, 407, 82, 107, 117, 256, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 104, 88, 381, 297, 98, 32, 56, 26, 141, 194, 226, 22, 21, 134, 476, 26, 480, 144, 30, 51, 36, 28, 224, 92, 25, 104, 226, 65, 38, 88, 283, 113, 103, 32, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_train_all)):\n",
    "    x_train_all[i] = [w for w in x_train_all[i] if w > 2]\n",
    "\n",
    "print(x_train_all[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnM909TXdVXl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=123)\n",
    "\n",
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxBu41lOdWSw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100) (5000, 100)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_len = 100\n",
    "x_train_seq = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_val_seq = sequence.pad_sequences(x_val, maxlen=max_len)\n",
    "\n",
    "print(x_train_seq.shape, x_val_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3SWcxgHePO6"
   },
   "source": [
    "# 모형의 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEBhruXKeTM8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UyMpeun8dq97"
   },
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "\n",
    "####################\n",
    "# TODO : 앞 선 실습에서 사용된 코드에서 SimpleRNN을 LSTM으로 변경하여 LSTM 모형을 생성하는\n",
    "# 코드를 작성하여 보시오,\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-3SFtHYXxoR"
   },
   "source": [
    "# 모델 컴파일 & 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6ezESOBX9eD"
   },
   "outputs": [],
   "source": [
    "model_lstmcompile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history=model_lstm.fit(x_train_seq, y_train, epochs=10, batch_size=32, \n",
    "                      validation_data=(x_val_seq, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PLTL3jMYoau"
   },
   "source": [
    "# 모형 훈련 결과 시각화하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHDstQ1jZdDW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgbQO65BZbMP"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhQHsThsYj9L"
   },
   "source": [
    "# 모형의 평가\n",
    "\n",
    "모형의 정확도 점수를 출력해 보면 SimpleRNN보다 성능이 향상 된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmQyZK_rYhnH"
   },
   "outputs": [],
   "source": [
    "loss, acc = model_lstm.evaluate(x_val_seq, y_val, verbose=0)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
